MIT License

Copyright (c) 2025 Prashant Soni

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

```plaintext:/Users/prashantsoni/Documents/2025/Machine Learning/logestic-regression/logs/.gitkeep
# Placeholder to track logs directory
```

```plaintext:/Users/prashantsoni/Documents/2025/Machine Learning/logestic-regression/data/.gitkeep
# Placeholder to track data directory structure
```

```dockerfile:/Users/prashantsoni/Documents/2025/Machine Learning/logestic-regression/Dockerfile
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY src/ ./src/
COPY scripts/ ./scripts/
COPY model/ ./model/

# Create necessary directories
RUN mkdir -p logs data

# Create non-root user
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app

USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Set Python path
ENV PYTHONPATH=/app

# Run the application
CMD ["uvicorn", "src.weather_prediction.api:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml:/Users/prashantsoni/Documents/2025/Machine Learning/logestic-regression/docker-compose.yml
version: '3.8'

services:
  weather-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: weather-prediction-api
    ports:
      - "8000:8000"
    environment:
      - HOST=0.0.0.0
      - PORT=8000
      - LOG_LEVEL=INFO
      - PYTHONPATH=/app
    volumes:
      - ./model:/app/model:ro
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
```

```makefile:/Users/prashantsoni/Documents/2025/Machine Learning/logestic-regression/Makefile
.PHONY: help install install-dev train run test lint format docker-build docker-run clean

help:
	@echo "Available commands:"
	@echo "  install      - Install production dependencies"
	@echo "  install-dev  - Install development dependencies"
	@echo "  train        - Train the model"
	@echo "  run          - Run the API server"
	@echo "  test         - Run tests"
	@echo "  lint         - Run code linters"
	@echo "  format       - Format code with black and isort"
	@echo "  docker-build - Build Docker image"
	@echo "  docker-run   - Run Docker container"
	@echo "  clean        - Remove generated files"

install:
	pip install -r requirements.txt

install-dev:
	pip install -r requirements-dev.txt

train:
	PYTHONPATH=. python scripts/train.py

run:
	PYTHONPATH=. uvicorn src.weather_prediction.api:app --reload --host 0.0.0.0 --port 8000

test:
	PYTHONPATH=. pytest

lint:
	flake8 src scripts --exclude=venv,env,.venv,__pycache__
	mypy src scripts --ignore-missing-imports
	pylint src scripts --disable=C0111,R0903 || true

format:
	black src scripts tests
	isort src scripts tests

docker-build:
	docker-compose build

docker-run:
	docker-compose up -d

docker-stop:
	docker-compose down

docker-logs:
	docker-compose logs -f

clean:
	find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	find . -type f -name "*.pyc" -delete
	find . -type f -name "*.pyo" -delete
	find . -type d -name "*.egg-info" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name ".mypy_cache" -exec rm -rf {} + 2>/dev/null || true
	rm -rf htmlcov/
	rm -f .coverage
```

```python:/Users/prashantsoni/Documents/2025/Machine Learning/logestic-regression/tests/test_weather_predictor.py
"""Unit tests for WeatherPredictor class."""
import pytest
import pandas as pd
import numpy as np
from pathlib import Path
import tempfile
import sys

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.weather_prediction.model import WeatherPredictor


@pytest.fixture
def sample_data():
    """Create sample weather data for testing."""
    return pd.DataFrame({
        'Location': ['Sydney', 'Melbourne', 'Brisbane'],
        'MinTemp': [15.0, 12.0, 18.0],
        'MaxTemp': [25.0, 22.0, 28.0],
        'Rainfall': [0.0, 2.0, 0.0],
        'Evaporation': [4.0, 3.0, 5.0],
        'Sunshine': [8.0, 6.0, 9.0],
        'WindGustDir': ['N', 'S', 'E'],
        'WindGustSpeed': [35.0, 40.0, 30.0],
        'WindDir9am': ['N', 'S', 'E'],
        'WindDir3pm': ['NE', 'SW', 'E'],
        'WindSpeed9am': [15.0, 20.0, 10.0],
        'WindSpeed3pm': [20.0, 25.0, 15.0],
        'Humidity9am': [70.0, 75.0, 65.0],
        'Humidity3pm': [60.0, 65.0, 55.0],
        'Pressure9am': [1015.0, 1012.0, 1018.0],
        'Pressure3pm': [1013.0, 1010.0, 1016.0],
        'Cloud9am': [5.0, 6.0, 4.0],
        'Cloud3pm': [4.0, 5.0, 3.0],
        'Temp9am': [20.0, 18.0, 22.0],
        'Temp3pm': [24.0, 21.0, 27.0],
        'RainToday': ['No', 'Yes', 'No'],
        'RainTomorrow': ['No', 'Yes', 'No']
    })


def test_initialization():
    """Test WeatherPredictor initialization."""
    predictor = WeatherPredictor()
    assert predictor is not None
    assert not predictor.is_fitted
    assert len(predictor.numerical_cols) == 16
    assert len(predictor.categorical_cols) == 5


def test_fit(sample_data):
    """Test model fitting."""
    predictor = WeatherPredictor()
    predictor.fit(sample_data)
    
    assert predictor.is_fitted
    assert 'train' in predictor.metrics
    assert 'accuracy' in predictor.metrics['train']


def test_predict_before_fit(sample_data):
    """Test that prediction raises error before fitting."""
    predictor = WeatherPredictor()
    test_input = sample_data.drop('RainTomorrow', axis=1).iloc[[0]]
    
    with pytest.raises(ValueError, match="Model must be fitted"):
        predictor.predict(test_input)


def test_predict_after_fit(sample_data):
    """Test prediction after fitting."""
    predictor = WeatherPredictor()
    predictor.fit(sample_data)
    
    test_input = sample_data.drop('RainTomorrow', axis=1).iloc[[0]]
    prediction, probability = predictor.predict(test_input)
    
    assert prediction in ['Yes', 'No']
    assert 0 <= probability <= 1


def test_save_and_load(sample_data):
    """Test saving and loading model."""
    with tempfile.TemporaryDirectory() as tmpdir:
        model_dir = Path(tmpdir) / "test_model"
        
        # Train and save
        predictor = WeatherPredictor()
        predictor.fit(sample_data)
        predictor.save(str(model_dir))
        
        # Check files exist
        assert (model_dir / "imputer.joblib").exists()
        assert (model_dir / "scaler.joblib").exists()
        assert (model_dir / "encoder.joblib").exists()
        assert (model_dir / "model.joblib").exists()
        
        # Load and test
        loaded_predictor = WeatherPredictor.load(str(model_dir))
        assert loaded_predictor.is_fitted
        
        test_input = sample_data.drop('RainTomorrow', axis=1).iloc[[0]]
        prediction, probability = loaded_predictor.predict(test_input)
        
        assert prediction in ['Yes', 'No']
        assert 0 <= probability <= 1


def test_missing_columns():
    """Test error handling for missing columns."""
    predictor = WeatherPredictor()
    invalid_data = pd.DataFrame({'Location': ['Sydney']})
    
    with pytest.raises(ValueError, match="Missing required columns"):
        predictor._validate_data(invalid_data, is_training=True)
```

```python:/Users/prashantsoni/Documents/2025/Machine Learning/logestic-regression/tests/test_api.py
"""Tests for FastAPI application."""
import pytest
from fastapi.testclient import TestClient
from unittest.mock import Mock, patch
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))


@pytest.fixture
def mock_model():
    """Create a mock weather predictor."""
    mock = Mock()
    mock.predict.return_value = ("Yes", 0.85)
    mock.numerical_cols = ['MinTemp', 'MaxTemp']
    mock.categorical_cols = ['Location', 'RainToday']
    mock.target_col = 'RainTomorrow'
    return mock


@pytest.fixture
def client(mock_model):
    """Create test client with mocked model."""
    with patch('src.weather_prediction.api.WeatherPredictor.load', return_value=mock_model):
        from src.weather_prediction.api import app
        with TestClient(app) as test_client:
            yield test_client


def test_root_endpoint(client):
    """Test root endpoint."""
    response = client.get("/")
    assert response.status_code == 200
    data = response.json()
    assert "message" in data
    assert "version" in data


def test_health_endpoint(client):
    """Test health check endpoint."""
    response = client.get("/health")
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "healthy"
    assert data["model_loaded"] is True


def test_predict_endpoint(client):
    """Test prediction endpoint."""
    payload = {
        "Location": "Sydney",
        "MinTemp": 18.0,
        "MaxTemp": 25.0,
        "Rainfall": 0.0,
        "Evaporation": 4.0,
        "Sunshine": 8.0,
        "WindGustDir": "NE",
        "WindGustSpeed": 35.0,
        "WindDir9am": "N",
        "WindDir3pm": "NE",
        "WindSpeed9am": 15.0,
        "WindSpeed3pm": 20.0,
        "Humidity9am": 70.0,
        "Humidity3pm": 60.0,
        "Pressure9am": 1015.0,
        "Pressure3pm": 1013.0,
        "Cloud9am": 5.0,
        "Cloud3pm": 4.0,
        "Temp9am": 20.0,
        "Temp3pm": 24.0,
        "RainToday": "No"
    }
    
    response = client.post("/api/v1/predict", json=payload)
    assert response.status_code == 200
    data = response.json()
    assert "will_rain_tomorrow" in data
    assert "probability" in data
    assert "timestamp" in data


def test_predict_invalid_input(client):
    """Test prediction with invalid input."""
    payload = {
        "Location": "Sydney",
        "MinTemp": 18.0,
        # Missing required fields
    }
    
    response = client.post("/api/v1/predict", json=payload)
    assert response.status_code == 422  # Validation error


def test_model_info_endpoint(client):
    """Test model info endpoint."""
    response = client.get("/api/v1/model/info")
    assert response.status_code == 200
    data = response.json()
    assert "model_type" in data
    assert "numerical_features" in data
    assert "categorical_features" in data
```

Finally, create a setup script to help organize the cleanup:

```bash:/Users/prashantsoni/Documents/2025/Machine Learning/logestic-regression/setup_structure.sh
#!/bin/bash

# Script to move old files to notebooks and clean up

echo "Setting up new project structure..."

# Create notebooks directory if it doesn't exist
mkdir -p notebooks

# Move notebook to notebooks directory
if [ -f "weather_prediction_system.ipynb" ]; then
    mv weather_prediction_system.ipynb notebooks/
    echo "âœ“ Moved notebook to notebooks/"
fi

# Remove old Python files (they're now in src/)
if [ -f "app.py" ] && [ -f "src/weather_prediction/api.py" ]; then
    rm app.py
    echo "âœ“ Removed old app.py"
fi

if [ -f "weather_predictor.py" ] && [ -f "src/weather_prediction/model.py" ]; then
    rm weather_predictor.py
    echo "âœ“ Removed old weather_predictor.py"
fi

if [ -f "config.py" ] && [ -f "src/weather_prediction/config.py" ]; then
    rm config.py
    echo "âœ“ Removed old config.py"
fi

if [ -f "train.py" ] && [ -f "scripts/train.py" ]; then
    rm train.py
    echo "âœ“ Removed old train.py"
fi

# Remove intermediate CSV files
echo "Cleaning up intermediate data files..."
rm -f data/test_dfs.csv data/train_inputs.csv data/train_target.csv 
rm -f data/validation_inputs.csv data/validation_target.csv
echo "âœ“ Removed intermediate CSV files"

# Create directories
mkdir -p logs model

echo "âœ“ Project structure updated successfully!"
echo ""
echo "New structure:"
tree -L 2 -I '__pycache__|*.pyc|.git|venv|env|.venv|model|data'
```

Now here are your **FINAL COMMANDS** to spin up and test the model:

## ðŸš€ **Commands to Spin Up and Test the Model**

```bash
# 1. Navigate to project directory
cd "/Users/prashantsoni/Documents/2025/Machine Learning/logestic-regression"

# 2. Clean up old structure (run the setup script)
chmod +x setup_structure.sh
./setup_structure.sh

# 3. Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 4. Install dependencies
pip install --upgrade pip
pip install -r requirements.txt
pip install -r requirements-dev.txt

# 5. Create .env file from example
cp .env.example .env

# 6. Train the model
PYTHONPATH=. python scripts/train.py

# 7. Run the API server
PYTHONPATH=. uvicorn src.weather_prediction.api:app --reload --host 0.0.0.0 --port 8000

# Or use make command:
make train  # Train model
make run    # Run API server

# 8. Test the API (in another terminal)
# Test health endpoint
curl http://localhost:8000/health

# Test prediction endpoint
curl -X POST "http://localhost:8000/api/v1/predict" \
     -H "Content-Type: application/json" \
     -d '{
           "Location": "Sydney",
           "MinTemp": 18.0,
           "MaxTemp": 25.0,
           "Rainfall": 0.0,
           "Evaporation": 4.0,
           "Sunshine": 8.0,
           "WindGustDir": "NE",
           "WindGustSpeed": 35.0,
           "WindDir9am": "N",
           "WindDir3pm": "NE",
           "WindSpeed9am": 15.0,
           "WindSpeed3pm": 20.0,
           "Humidity9am": 70.0,
           "Humidity3pm": 60.0,
           "Pressure9am": 1015.0,
           "Pressure3pm": 1013.0,
           "Cloud9am": 5.0,
           "Cloud3pm": 4.0,
           "Temp9am": 20.0,
           "Temp3pm": 24.0,
           "RainToday": "No"
         }'

# 9. Run tests
PYTHONPATH=. pytest -v

# 10. View API documentation
# Open browser: http://localhost:8000/docs
```

## ðŸ³ **Docker Commands:**

```bash
# Build and run with Docker Compose
make docker-build
make docker-run

# Or directly:
docker-compose up --build -d

# View logs
docker-compose logs -f

# Test Docker deployment
curl http://localhost:8000/health

# Stop Docker
docker-compose down
```

## ðŸ“¤ **Push to GitHub:**

```bash
# Initialize git (if not already done)
git init

# Add all files
git add .

# Create commit
git commit -m "feat: Production-ready weather prediction system with restructured architecture

- Reorganized code into src/weather_prediction package
- Moved training script to scripts/
- Added comprehensive testing suite
- Added Docker and CI/CD support
- Added configuration management and logging
- Updated documentation and structure"

# Create repository on GitHub, then:
git remote add origin https://github.com/YOUR_USERNAME/weather-prediction-system.git
git branch -M main
git push -u origin main
```

Your project is now fully production-ready with a clean, professional structure! ðŸŽ‰
```

